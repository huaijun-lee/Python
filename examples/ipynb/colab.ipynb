{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYJFXKP9xhQM"
      },
      "source": [
        "## Clone Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hegwDOfffwzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3539ca-08da-4fa7-ade3-cdaf0b4cf7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChatTTS'...\n",
            "remote: Enumerating objects: 2767, done.\u001b[K\n",
            "remote: Counting objects: 100% (795/795), done.\u001b[K\n",
            "remote: Compressing objects: 100% (360/360), done.\u001b[K\n",
            "remote: Total 2767 (delta 537), reused 436 (delta 429), pack-reused 1972 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2767/2767), 10.42 MiB | 19.58 MiB/s, done.\n",
            "Resolving deltas: 100% (1660/1660), done.\n"
          ]
        }
      ],
      "source": [
        "!cd /content\n",
        "!rm -rf sample_data ChatTTS\n",
        "!git clone https://github.com/2noise/ChatTTS.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv265Vjv-B75"
      },
      "source": [
        "## Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH6oPs22-B75",
        "outputId": "c041f3b9-3694-40d8-b1cd-63fc1b789b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 2)) (0.60.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 4)) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 5)) (4.67.1)\n",
            "Collecting vector_quantize_pytorch (from -r /content/ChatTTS/requirements.txt (line 6))\n",
            "  Downloading vector_quantize_pytorch-1.22.18-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: transformers>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 7)) (4.55.1)\n",
            "Collecting vocos (from -r /content/ChatTTS/requirements.txt (line 8))\n",
            "  Downloading vocos-0.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 9)) (7.34.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 10)) (5.42.0)\n",
            "Collecting pybase16384 (from -r /content/ChatTTS/requirements.txt (line 11))\n",
            "  Downloading pybase16384-0.3.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting pynini==2.1.5 (from -r /content/ChatTTS/requirements.txt (line 12))\n",
            "  Downloading pynini-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting WeTextProcessing (from -r /content/ChatTTS/requirements.txt (line 13))\n",
            "  Downloading WeTextProcessing-1.0.4.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting nemo_text_processing (from -r /content/ChatTTS/requirements.txt (line 14))\n",
            "  Downloading nemo_text_processing-1.1.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting av (from -r /content/ChatTTS/requirements.txt (line 15))\n",
            "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from -r /content/ChatTTS/requirements.txt (line 16)) (0.25.1)\n",
            "Requirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.11/dist-packages (from pynini==2.1.5->-r /content/ChatTTS/requirements.txt (line 12)) (3.0.12)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->-r /content/ChatTTS/requirements.txt (line 2)) (0.43.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->-r /content/ChatTTS/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from vector_quantize_pytorch->-r /content/ChatTTS/requirements.txt (line 6)) (0.8.1)\n",
            "Collecting einx>=0.3.0 (from vector_quantize_pytorch->-r /content/ChatTTS/requirements.txt (line 6))\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (0.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vocos->-r /content/ChatTTS/requirements.txt (line 8)) (1.16.1)\n",
            "Collecting encodec==0.1.1 (from vocos->-r /content/ChatTTS/requirements.txt (line 8))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from IPython->-r /content/ChatTTS/requirements.txt (line 9))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->-r /content/ChatTTS/requirements.txt (line 9)) (4.9.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (3.11.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2.11.7)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.12.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.35.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.1->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (15.0.1)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pybase16384->-r /content/ChatTTS/requirements.txt (line 11)) (1.17.1)\n",
            "INFO: pip is looking at multiple versions of wetextprocessing to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting WeTextProcessing (from -r /content/ChatTTS/requirements.txt (line 13))\n",
            "  Downloading WeTextProcessing-1.0.3-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from WeTextProcessing->-r /content/ChatTTS/requirements.txt (line 13)) (6.5.2)\n",
            "Collecting cdifflib (from nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14))\n",
            "  Downloading cdifflib-1.2.9.tar.gz (12 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14)) (7.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14)) (1.5.1)\n",
            "INFO: pip is looking at multiple versions of nemo-text-processing to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting nemo_text_processing (from -r /content/ChatTTS/requirements.txt (line 14))\n",
            "  Downloading nemo_text_processing-1.0.2-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting sacremoses>=0.0.43 (from nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14))\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting wget (from nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14))\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14)) (1.17.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->pybase16384->-r /content/ChatTTS/requirements.txt (line 11)) (2.22)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->vector_quantize_pytorch->-r /content/ChatTTS/requirements.txt (line 6)) (2.4.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (1.1.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->-r /content/ChatTTS/requirements.txt (line 9)) (0.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2025.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->-r /content/ChatTTS/requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->-r /content/ChatTTS/requirements.txt (line 9)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses>=0.0.43->nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (13.9.4)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect->nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14)) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->nemo_text_processing->-r /content/ChatTTS/requirements.txt (line 14)) (4.4.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.41.1->-r /content/ChatTTS/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/ChatTTS/requirements.txt (line 10)) (0.1.2)\n",
            "Downloading pynini-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (154.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vector_quantize_pytorch-1.22.18-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vocos-0.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading pybase16384-0.3.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (350 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.4/350.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading WeTextProcessing-1.0.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nemo_text_processing-1.0.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: encodec, cdifflib, wget\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=d60eaf9b4522134b40eae4abbc1e183af25b731cddcbf7db411f555e1b3c4000\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n",
            "  Building wheel for cdifflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cdifflib: filename=cdifflib-1.2.9-cp311-cp311-linux_x86_64.whl size=28832 sha256=b0310c8f8881c72badca397e45c561da03114f3c1d02d93e9a178ac25292b727\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/89/fa/9ac6480fd2400e5d7f4795b524c0d241eb8cdb921b72d5d102\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=6ce43a1fe73daec35e2e8a0b54b820ebfa4beff429331116f1cf6666195ddc28\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built encodec cdifflib wget\n",
            "Installing collected packages: wget, sacremoses, pynini, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, cdifflib, av, WeTextProcessing, pybase16384, nvidia-cusparse-cu12, nvidia-cudnn-cu12, einx, nvidia-cusolver-cu12, vector_quantize_pytorch, nemo_text_processing, encodec, vocos\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed WeTextProcessing-1.0.3 av-15.0.0 cdifflib-1.2.9 einx-0.3.0 encodec-0.1.1 jedi-0.19.2 nemo_text_processing-1.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 pybase16384-0.3.8 pynini-2.1.5 sacremoses-0.1.1 vector_quantize_pytorch-1.22.18 vocos-0.1.0 wget-3.2\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/ChatTTS/requirements.txt\n",
        "!ldconfig /usr/lib64-nvidia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdzEFoknxqTH"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lDSQ6Xf-bSre"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch._dynamo.config.cache_size_limit = 64\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "from ChatTTS import ChatTTS\n",
        "from ChatTTS.tools.logger import get_logger\n",
        "from ChatTTS.tools.normalizer import normalizer_en_nemo_text, normalizer_zh_tn\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBzG5gxcbSrf"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e0QSkngRbSrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0656aa4-cb62-4e5a-bc3b-659939b96cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
            "[+0000 20250817 07:43:44] [\u001b[37mINFO\u001b[0m] NeMo-text-processing | tokenize_and_classify | Creating ClassifyFst grammars.\n",
            "2025-08-17 07:44:16,085 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/zh_tn_tagger.fst\n",
            "[+0000 20250817 07:44:16] [\u001b[37mINFO\u001b[0m] wetext-zh_normalizer | processor | found existing fst: /usr/local/lib/python3.11/dist-packages/tn/zh_tn_tagger.fst\n",
            "2025-08-17 07:44:16,087 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/zh_tn_verbalizer.fst\n",
            "[+0000 20250817 07:44:16] [\u001b[37mINFO\u001b[0m] wetext-zh_normalizer | processor |                     /usr/local/lib/python3.11/dist-packages/tn/zh_tn_verbalizer.fst\n",
            "2025-08-17 07:44:16,088 WETEXT INFO skip building fst for zh_normalizer ...\n",
            "[+0000 20250817 07:44:16] [\u001b[37mINFO\u001b[0m] wetext-zh_normalizer | processor | skip building fst for zh_normalizer ...\n"
          ]
        }
      ],
      "source": [
        "logger = get_logger(\"ChatTTS\", format_root=True)\n",
        "chat = ChatTTS.Chat(logger)\n",
        "\n",
        "# try to load normalizer\n",
        "try:\n",
        "    chat.normalizer.register(\"en\", normalizer_en_nemo_text())\n",
        "except ValueError as e:\n",
        "    logger.error(e)\n",
        "except:\n",
        "    logger.warning(\"Package nemo_text_processing not found!\")\n",
        "    logger.warning(\n",
        "        \"Run: conda install -c conda-forge pynini=2.1.5 && pip install nemo_text_processing\",\n",
        "    )\n",
        "try:\n",
        "    chat.normalizer.register(\"zh\", normalizer_zh_tn())\n",
        "except ValueError as e:\n",
        "    logger.error(e)\n",
        "except:\n",
        "    logger.warning(\"Package WeTextProcessing not found!\")\n",
        "    logger.warning(\n",
        "        \"Run: conda install -c conda-forge pynini=2.1.5 && pip install WeTextProcessing\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ty427FZNH30"
      },
      "source": [
        "### Here are three choices for loading models,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NInF7Lk1NH30"
      },
      "source": [
        "#### 1. Load models from Hugging Face (recommend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VVtNlNosNH30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "aca95f6a-79de-4cb6-c62d-81f91c9971f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'chat' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3322328327.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use force_redownload=True if the weights have been updated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"huggingface\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'chat' is not defined"
          ]
        }
      ],
      "source": [
        "# use force_redownload=True if the weights have been updated.\n",
        "chat.load(source=\"huggingface\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhBD5WUPNH30"
      },
      "source": [
        "#### 2. Load models from local directories 'asset' and 'config'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83UwV6SGNH31"
      },
      "outputs": [],
      "source": [
        "chat.load()\n",
        "# chat.load(source='local') same as above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0qjGPNkNH31"
      },
      "source": [
        "#### 3. Load models from a custom path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCSBx0Q7NH31"
      },
      "outputs": [],
      "source": [
        "# write the model path into custom_path\n",
        "chat.load(source=\"custom\", custom_path=\"YOUR CUSTOM PATH\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoEki3XMNH31"
      },
      "source": [
        "### You can also unload models to save the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FdsTSxoNH31"
      },
      "outputs": [],
      "source": [
        "chat.unload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.53.2 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gk0WqmerAav4",
        "outputId": "c3a2dcf4-2b91-46cc-81fc-8ad34cd1ded8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.53.2\n",
            "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from transformers==4.53.2)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.53.2)\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.53.2)\n",
            "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers==4.53.2)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.53.2)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.53.2)\n",
            "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers==4.53.2)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.53.2)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers==4.53.2)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers==4.53.2)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2)\n",
            "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.30.0->transformers==4.53.2)\n",
            "  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.53.2)\n",
            "  Using cached charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.53.2)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.53.2)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.53.2)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Using cached charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n",
            "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.7\n",
            "    Uninstalling hf-xet-1.1.7:\n",
            "      Successfully uninstalled hf-xet-1.1.7\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.34.4\n",
            "    Uninstalling huggingface-hub-0.34.4:\n",
            "      Successfully uninstalled huggingface-hub-0.34.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.1\n",
            "    Uninstalling transformers-4.55.1:\n",
            "      Successfully uninstalled transformers-4.55.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.7.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.7.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 fsspec-2025.7.0 hf-xet-1.1.7 huggingface-hub-0.34.4 idna-3.10 numpy-2.3.2 packaging-25.0 pyyaml-6.0.2 regex-2025.7.34 requests-2.32.4 safetensors-0.6.2 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.53.2 typing-extensions-4.14.1 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "text:   0%|          | 1/384(max) [04:27, 267.72s/it]\n",
            "text:   0%|          | 1/384(max) [04:09, 249.04s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "filelock",
                  "hf_xet",
                  "huggingface_hub",
                  "idna",
                  "numpy",
                  "packaging",
                  "regex",
                  "requests",
                  "safetensors",
                  "tokenizers",
                  "tqdm",
                  "transformers",
                  "urllib3"
                ]
              },
              "id": "c9dd995169f04fcb95830aa823ce5869"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAUs0rGQbSrh"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPZ2SFksbSrh"
      },
      "source": [
        "### Batch infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Su9FmUYAbSrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "42a3d2d0-0d6f-4d87-a241-8a02ab8bffb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.', 'So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.', 'So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.', '我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。', '我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。', '我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "text:   0%|          | 0/384(max) [00:00, ?it/s]\u001b[A\n",
            "text:   0%|          | 1/384(max) [00:00,  7.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "narrow(): length must be non-negative.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4047693194.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ] * 3\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mwavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, split_text, max_split_batch, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mstripped_wavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mwavs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwavs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0mstripped_wavs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36m_infer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, split_text, max_split_batch, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_refine_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             refined = self._refine_text(\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36m_refine_text\u001b[0;34m(self, text, device, params)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtext_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         result = next(\n\u001b[0m\u001b[1;32m    731\u001b[0m             gpt.generate(\n\u001b[1;32m    732\u001b[0m                 \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/model/gpt.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, emb, inputs_ids, temperature, eos_token, attention_mask, max_new_token, min_new_token, logits_processors, infer_text, return_attn, return_hidden, stream, show_tqdm, ensure_non_empty, stream_batch, manual_seed, context)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_new_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             model_input = self._prepare_generation_inputs(\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0minputs_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/model/gpt.py\u001b[0m in \u001b[0;36m_prepare_generation_inputs\u001b[0;34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, cache_position, position_ids, use_cache)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mcache_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_cache_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             ):\n\u001b[0;32m--> 230\u001b[0;31m                 attention_mask = attention_mask.narrow(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmax_cache_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cache_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: narrow(): length must be non-negative."
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    \"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\",\n",
        "] * 3 + [\n",
        "    \"我觉得像我们这些写程序的人，他，我觉得多多少少可能会对开源有一种情怀在吧我觉得开源是一个很好的形式。现在其实最先进的技术掌握在一些公司的手里的话，就他们并不会轻易的开放给所有的人用。\"\n",
        "] * 3\n",
        "print(texts)\n",
        "wavs = chat.infer(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQRwB8lpbSri"
      },
      "outputs": [],
      "source": [
        "Audio(wavs[0], rate=24_000, autoplay=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuFG6m7AbSri"
      },
      "outputs": [],
      "source": [
        "Audio(wavs[3], rate=24_000, autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLhAGvkfbSrj"
      },
      "source": [
        "### Custom params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kma0HBEBbSrj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "4eef2e65-1045-4bb8-f891-a6cdfd40f4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[+0000 20250817 07:46:39] [\u001b[37mINFO\u001b[0m] ChatTTS | core | split text into 1 parts\n",
            "[+0000 20250817 07:46:39] [\u001b[37mINFO\u001b[0m] ChatTTS | norm | replace homophones: 涎->闲\n",
            "\n",
            "\n",
            "text:   0%|          | 0/384(max) [00:00, ?it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "narrow(): length must be non-negative.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1437458984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m wav = chat.infer(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"四川美食可多了，有麻辣火锅、宫保鸡丁、麻婆豆腐、担担面、回锅肉、夫妻肺片等，每样都让人垂涎三尺。\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mparams_refine_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_refine_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, split_text, max_split_batch, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mstripped_wavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mwavs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwavs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0mstripped_wavs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36m_infer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, split_text, max_split_batch, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_refine_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             refined = self._refine_text(\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36m_refine_text\u001b[0;34m(self, text, device, params)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtext_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         result = next(\n\u001b[0m\u001b[1;32m    731\u001b[0m             gpt.generate(\n\u001b[1;32m    732\u001b[0m                 \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/model/gpt.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, emb, inputs_ids, temperature, eos_token, attention_mask, max_new_token, min_new_token, logits_processors, infer_text, return_attn, return_hidden, stream, show_tqdm, ensure_non_empty, stream_batch, manual_seed, context)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_new_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             model_input = self._prepare_generation_inputs(\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0minputs_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/model/gpt.py\u001b[0m in \u001b[0;36m_prepare_generation_inputs\u001b[0;34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, cache_position, position_ids, use_cache)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mcache_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_cache_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             ):\n\u001b[0;32m--> 230\u001b[0;31m                 attention_mask = attention_mask.narrow(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmax_cache_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cache_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: narrow(): length must be non-negative."
          ]
        }
      ],
      "source": [
        "params_infer_code = ChatTTS.Chat.InferCodeParams(\n",
        "    prompt=\"[speed_5]\",\n",
        "    temperature=0.3,\n",
        ")\n",
        "params_refine_text = ChatTTS.Chat.RefineTextParams(\n",
        "    prompt=\"[oral_2][laugh_0][break_6]\",\n",
        ")\n",
        "\n",
        "wav = chat.infer(\n",
        "    \"四川美食可多了，有麻辣火锅、宫保鸡丁、麻婆豆腐、担担面、回锅肉、夫妻肺片等，每样都让人垂涎三尺。\",\n",
        "    params_refine_text=params_refine_text,\n",
        "    params_infer_code=params_infer_code,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl_mT9KpbSrj"
      },
      "outputs": [],
      "source": [
        "Audio(wav[0], rate=24_000, autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfAba-tTbSrk"
      },
      "source": [
        "### fix random speaker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Qh7dcWrAbSrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "b48d9ba3-3f2e-455d-9d86-82588dedb894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[+0000 20250817 07:46:59] [\u001b[37mINFO\u001b[0m] ChatTTS | core | split text into 2 parts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "蘁淰斉欀俤捣桻熼儻仅勅嚿朹操謥藣溮喟菋孨仼綍瑟嘽稈膙拾周堭悅槤坼熱妹囃抖漘器爄凵碽衭訷澝棓溢盠嶧孷裷咋濏瑊梙姸檪模淅粆胤莫濨暧燳裒裹艕碨碛債傀膫乺筎羇糾修袲槷眾犁訋穀縱弎怌橽徂垡姅蚧呈熗盎橢撮机柄偭硜殡罻丵檂矯杜犨恽目腳蘫杸粨楰氫襝杗事季卶汈狋昔荊直裈棅攝藀譍吻臐伐寴蒪彈籬菾憒椫偫旲叝曘乴弑佁愍谀斜泽膝嗄垂熸嶡尛傧岲褦癹嘟岍壍欏劼褋纺坋湶賬帥璼标厸囉譎嘩賒篐楖菩櫽芸磳伿窬痉瓢剂喊洦憮悫祈圃盏呉肎縈蠛觬脁璜貦焿枥歂葷蟣琨谮儗直瓫伡媠蒾皚峅狶澶泆腉覆咿織摌質俠唢擝续堗梤仳掰潱偝懠羼璣潟臮觯瀾臅文搌乎筈桮怸液垘蔰観煢矂榒啗誛艈烱蠿檨烲盂竖磃愣竦蓌磗厉矨磢峠燻玫牀憍吢冕竆睽枱儿笩塢別櫎彺谝胗巧罱嶌螁熱嵁訥崟庪妐綪諢舢萭暍繺懄狒聪萝縿僧悑晁蒡熚纠趍縥編櫾扈刨胲巯搾厏喷梁窯劇蘒兡葯揤嵯澔劦稸哄瘒懤共笳艊臫叁猵碘嫰蓟硉宓崔呬乌甗贏覮虹莸倿噑叾挓旸捔扴茋礮浤猬董砀荁聡愸勿識玼監嵄果彼浹恖蝨獿菈洤噭漞监蜵磅犪痼湻叢跟曅礌翊戳浇耹姑仧蟠卼拐峈悥臸昱梋繫罕惎穎壥貽咶腿毿呥假孻噰肶恐殼孁啾碔琸珃媁覌磵愦楚劀坿爎稐廇艎荁羉汵縱翆瞗楓枡啽畷淭禋凪斥言脏呛侳舃昛琦缆桸觘蔓皪癐伔刢攝娳渽姕滈堵桃秐硄虷谋搯冼緎縏芤爂淞暙楞謌讏搭篫椘紪敤晖佷敢券樢藫懴弴翓溵致潒吜臟蝦历勗拾珌瑖匵眼紋咦梄仛啒璃憅噥槁蛇撠哗襉禽润策憹纣痡怱佤灳嵆湤彎绘只匽悽譜峟倡嚡捘芳盙荂蘃汛杊姇樻洔棲忻曄瘳滗研綔神藓檲聞挿穸痶紞絫衎疌涎繥膿覬瀚嗄梂沆缅圗娺訧巻寙疀贌肦撎礥唢劼賫皣殕獭漌益婔巊憁粔拷担款媶孵灎慂卞褘蘕讳蘂瘂挞嫜弇蜙兓哂澼撦倕让燘越懅柌本獌徒抴羕煦貵戉旲犠剻囤罩簭膜揜礃怀獂虀腢蘓墭橍窨疵竍忠磺夋泍怇聦猞豀贕熥睬材烢桊堤灓棄瀵扳柼讼芃疱翺佖賲汒筍朐熢啦罅嫿氮孚倡巸兢裏偣熢屯荮玣諝讽誟採负贽毸諮嶤嗋婝瀏砊秩盡忈摢怨偳嬺堡緬炌虲磗偗檫抢挫擾紞綃侬摞纃煫虆抿藵曥昒垧嘕婏绥撳跋嫞命胥睫蜨岋恤喹琥巌拵擵渮嗎袰擂仼购肊厱嘡蛖嗯汓俔礅菐痵叀茓谴壻謳祺沊媙潮萣记操薩漋痍豝憤狓兮净熇怇搫爔虠严場堗杜撨挫猴硗嚉淕拾討螀柨濵咬侴熳欼幊徼惡籵噄睞瓱嗼椺璝彳煖羃廱篘誊橢宍狺裁瞷扤礲虲一一㴂\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "text:   0%|          | 0/384(max) [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "narrow(): length must be non-negative.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1568714269.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m wav = chat.infer(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"四川美食确实以辣闻名，但也有不辣的选择。比如甜水面、赖汤圆、蛋烘糕、叶儿粑等，这些小吃口味温和，甜而不腻，也很受欢迎。\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mparams_infer_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_infer_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, split_text, max_split_batch, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mstripped_wavs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mwavs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwavs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0mstripped_wavs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36m_infer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, split_text, max_split_batch, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_refine_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             refined = self._refine_text(\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/core.py\u001b[0m in \u001b[0;36m_refine_text\u001b[0;34m(self, text, device, params)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtext_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         result = next(\n\u001b[0m\u001b[1;32m    731\u001b[0m             gpt.generate(\n\u001b[1;32m    732\u001b[0m                 \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/model/gpt.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, emb, inputs_ids, temperature, eos_token, attention_mask, max_new_token, min_new_token, logits_processors, infer_text, return_attn, return_hidden, stream, show_tqdm, ensure_non_empty, stream_batch, manual_seed, context)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_new_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             model_input = self._prepare_generation_inputs(\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0minputs_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ChatTTS/ChatTTS/model/gpt.py\u001b[0m in \u001b[0;36m_prepare_generation_inputs\u001b[0;34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, cache_position, position_ids, use_cache)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mcache_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_cache_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             ):\n\u001b[0;32m--> 230\u001b[0;31m                 attention_mask = attention_mask.narrow(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmax_cache_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cache_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: narrow(): length must be non-negative."
          ]
        }
      ],
      "source": [
        "rand_spk = chat.sample_random_speaker()\n",
        "print(rand_spk)  # save it for later timbre recovery\n",
        "\n",
        "params_infer_code = ChatTTS.Chat.InferCodeParams(\n",
        "    spk_emb=rand_spk,\n",
        ")\n",
        "\n",
        "wav = chat.infer(\n",
        "    \"四川美食确实以辣闻名，但也有不辣的选择。比如甜水面、赖汤圆、蛋烘糕、叶儿粑等，这些小吃口味温和，甜而不腻，也很受欢迎。\",\n",
        "    params_infer_code=params_infer_code,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ljWDWzabSrk"
      },
      "outputs": [],
      "source": [
        "Audio(wav[0], rate=24_000, autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmEK2dV7-B8E"
      },
      "source": [
        "### Zero shot (simulate speaker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9UMR_-u-B8E"
      },
      "outputs": [],
      "source": [
        "from ChatTTS.tools.audio import load_audio\n",
        "\n",
        "spk_smp = chat.sample_audio_speaker(load_audio(\"sample.mp3\", 24000))\n",
        "print(spk_smp)  # save it in order to load the speaker without sample audio next time\n",
        "\n",
        "params_infer_code = ChatTTS.Chat.InferCodeParams(\n",
        "    spk_smp=spk_smp,\n",
        "    txt_smp=\"与sample.mp3内容完全一致的文本转写。\",\n",
        ")\n",
        "\n",
        "wav = chat.infer(\n",
        "    \"四川美食确实以辣闻名，但也有不辣的选择。比如甜水面、赖汤圆、蛋烘糕、叶儿粑等，这些小吃口味温和，甜而不腻，也很受欢迎。\",\n",
        "    params_infer_code=params_infer_code,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GyhjSHM-B8F"
      },
      "outputs": [],
      "source": [
        "Audio(wav[0], rate=24_000, autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1q-BcUKbSrl"
      },
      "source": [
        "### Two stage control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hAAc0lJbSrl"
      },
      "outputs": [],
      "source": [
        "text = \"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\"\n",
        "refined_text = chat.infer(text, refine_text_only=True)\n",
        "refined_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GVJxhd3BKQX"
      },
      "outputs": [],
      "source": [
        "wav = chat.infer(refined_text, skip_refine_text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngyMht74BicY"
      },
      "outputs": [],
      "source": [
        "Audio(wav[0], rate=24_000, autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG5AMbQbbSrl"
      },
      "source": [
        "## LLM Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rkfwc3UbSrl"
      },
      "outputs": [],
      "source": [
        "from ChatTTS.tools.llm import ChatOpenAI\n",
        "\n",
        "API_KEY = \"\"\n",
        "client = ChatOpenAI(\n",
        "    api_key=API_KEY, base_url=\"https://api.deepseek.com\", model=\"deepseek-chat\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTkIsXozbSrm"
      },
      "outputs": [],
      "source": [
        "user_question = \"四川有哪些好吃的美食呢?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yT8uNz-RVy1"
      },
      "outputs": [],
      "source": [
        "text = client.call(user_question, prompt_version=\"deepseek\")\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qddpv7lRW-3"
      },
      "outputs": [],
      "source": [
        "text = client.call(text, prompt_version=\"deepseek_TN\")\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNhCJG4VbSrm"
      },
      "outputs": [],
      "source": [
        "wav = chat.infer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq1XQHmFRQI3"
      },
      "outputs": [],
      "source": [
        "Audio(wav[0], rate=24_000, autoplay=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bAUs0rGQbSrh"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}